\# Architecture Overview\## PurposeThis platform demonstrates an architect-level approach to operationalizing AI models on AWS using Kubernetes, Infrastructure as Code, and secure CI/CD pipelines.The focus is on \*\*platform design, governance, and reliability\*\*, not experimental data science.\## Core Components\### Artifact Management\- Versioned model artifacts stored in Amazon S3\- Immutable artifact paths\- Pointer file used to promote active versions\### Runtime Platform\- Amazon EKS (Kubernetes)\- Stateless inference service\- Horizontal Pod Autoscaling\- AWS ALB Ingress Controller\### CI/CD \& Automation\- GitHub Actions for build, publish, and deploy workflows\- OIDC-based authentication to AWS\- Environment-aware deployment strategy\### Security\- No static cloud credentials\- IAM Roles for Service Accounts (IRSA)\- Least-privilege IAM policies\### Observability \& Operations\- Centralized logging via CloudWatch\- Health and readiness probes\- Scheduled drift evaluation jobs\- Incident signaling through GitHub Issues\## High-Level Flow1\. Model artifact is generated and published to S3 with metadata.2\. Container image is built and pushed to ECR.3\. Deployment pipeline updates the Kubernetes workload via Helm.4\. Runtime loads the active artifact version during startup.5\. Monitoring jobs continuously evaluate service and model health.